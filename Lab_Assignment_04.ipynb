{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Root-0/CSE317-Lab/blob/main/Lab_Assignment_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c7AUZ3jMJY_"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirsazzathossain/CSE317-Lab/blob/autumn_2022/Lab_Assignment_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAPQiFOHL9aw"
      },
      "source": [
        "#### **Polynomial Regression**\n",
        "\n",
        "In this assignment, you will implement polynomial regression and apply it to the [Assignment 4 Dataset](https://minhaskamal.github.io/DownGit/#/home?url=https://github.com/mirsazzathossain/CSE317-Lab-Numerical-Methods/blob/main/datasets/data.csv).\n",
        "\n",
        "The dataset contains two columns, the first column is the feature and the second column is the label. The goal is find the best fit line for the data.\n",
        "\n",
        "You will need to perform the following regression tasks and find the best one for the dataset.\n",
        "\n",
        "1.    **Linear Regression:**\n",
        "\n",
        "     The equation we are trying to fit is:\n",
        "     $$y = \\theta_0 + \\theta_1 x$$\n",
        "     where $x$ is the feature and $y$ is the label.\n",
        "\n",
        "     We can rewrite the equation in vector form as:\n",
        "$$Y = X\\theta$$ where $X$ is a matrix with two columns, the first column is all 1s and the second column is the feature, and $Y$ is a vector with the labels. $\\theta$ is a vector with two elements, $\\theta_0$ and $\\theta_1$. The $X$ matrix will look like this:\n",
        "$$X = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix}$$\n",
        "2. **Quadratic Regression:**\n",
        "\n",
        "     The equation we are trying to fit is:\n",
        "     $$y = \\theta_0 + \\theta_1 x + \\theta_2 x^2$$\n",
        "     where $x$ is the feature and $y$ is the label.\n",
        "\n",
        "     We can rewrite the equation in vector form as:\n",
        "$$Y = X\\theta$$where $X$ is a matrix with three columns, the first column is all 1s, the second column is the feature, and the third column is the feature squared, and $Y$ is a vector with the labels. $\\theta$ is a vector with three elements, $\\theta_0$, $\\theta_1$, and $\\theta_2$. The $X$ matrix will look like this:\n",
        "\n",
        "$$X = \\begin{bmatrix} 1 & x_1 & x_1^2 \\\\ 1 & x_2 & x_2^2 \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & x_n & x_n^2 \\end{bmatrix}$$\n",
        "3. **Cubic Regression:**\n",
        "\n",
        "     The equation we are trying to fit is:\n",
        "$$y = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3$$\n",
        "     where $x$ is the feature and $y$ is the label.\n",
        "\n",
        "     We can rewrite the equation in vector form as:\n",
        "$$Y = X\\theta$$where $X$ is a matrix with four columns, the first column is all 1s, the second column is the feature, the third column is the feature squared, and the fourth column is the feature cubed, and $Y$ is a vector with the labels. $\\theta$ is a vector with four elements, $\\theta_0$, $\\theta_1$, $\\theta_2$, and $\\theta_3$. The $X$ matrix will look like this:\n",
        "$$X = \\begin{bmatrix} 1 & x_1 & x_1^2 & x_1^3 \\\\ 1 & x_2 & x_2^2 & x_2^3 \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ 1 & x_n & x_n^2 & x_n^3 \\end{bmatrix}$$\n",
        "\n",
        "Take 15 data points from the dataset and use them as the training set. Use the remaining data points as the test set. For each regression task, find the best $\\theta$ vector using the training set. Then, calculate the mean squared error (MSE) on the test set. Plot the training set, the test set (in a different color), and the best fit line for each regression task. Which regression task gives the best fit line? Which regression task gives the lowest MSE on the test set? Report your answers in a Markdown cell.\n",
        "\n",
        "**Note:** Do not use any built-in functions like `np.polyfit` or `sklearn.linear_model.LinearRegression` or any other built-in functions that perform polynomial regression. You must implement the regression tasks yourself."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and split data\n",
        "def load_and_split_data(filename, train_size=15):\n",
        "    data = np.loadtxt(filename)\n",
        "    x = data[:, 0]\n",
        "    y = data[:, 1]\n",
        "\n",
        "    # Split into train and test\n",
        "    x_train = x[:train_size]\n",
        "    y_train = y[:train_size]\n",
        "    x_test = x[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "def create_polynomial_features(x, degree):\n",
        "    \"\"\"Create matrix X with polynomial features up to given degree\"\"\"\n",
        "    n = len(x)\n",
        "    X = np.ones((n, degree + 1))\n",
        "    for d in range(1, degree + 1):\n",
        "        X[:, d] = x ** d\n",
        "    return X\n",
        "\n",
        "def fit_polynomial(X, y):\n",
        "    \"\"\"Compute theta using normal equation: Î¸ = (X^T X)^(-1) X^T y\"\"\"\n",
        "    return np.linalg.inv(X.T @ X) @ X.T @ y\n",
        "\n",
        "def calculate_mse(X, y, theta):\n",
        "    \"\"\"Calculate Mean Squared Error\"\"\"\n",
        "    predictions = X @ theta\n",
        "    return np.mean((predictions - y) ** 2)\n",
        "\n",
        "def plot_regression(x_train, y_train, x_test, y_test, theta, degree, title):\n",
        "    \"\"\"Plot data points and regression curve\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot training and test points\n",
        "    plt.scatter(x_train, y_train, color='blue', label='Training Data')\n",
        "    plt.scatter(x_test, y_test, color='red', label='Test Data')\n",
        "\n",
        "    # Generate points for smooth curve\n",
        "    x_curve = np.linspace(min(x_train.min(), x_test.min()),\n",
        "                         max(x_train.max(), x_test.max()), 100)\n",
        "    X_curve = create_polynomial_features(x_curve, degree)\n",
        "    y_curve = X_curve @ theta\n",
        "\n",
        "    plt.plot(x_curve, y_curve, color='green', label='Regression Line')\n",
        "    plt.title(f'{title} (Degree {degree})')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('y')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Main execution\n",
        "def run_polynomial_regression(filename):\n",
        "    # Load and split data\n",
        "    x_train, y_train, x_test, y_test = load_and_split_data(filename)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Run regression for degrees 1, 2, and 3\n",
        "    for degree in [1, 2, 3]:\n",
        "        # Create feature matrices\n",
        "        X_train = create_polynomial_features(x_train, degree)\n",
        "        X_test = create_polynomial_features(x_test, degree)\n",
        "\n",
        "        # Fit model\n",
        "        theta = fit_polynomial(X_train, y_train)\n",
        "\n",
        "        # Calculate MSE\n",
        "        train_mse = calculate_mse(X_train, y_train, theta)\n",
        "        test_mse = calculate_mse(X_test, y_test, theta)\n",
        "\n",
        "        # Plot results\n",
        "        plot_regression(x_train, y_train, x_test, y_test, theta,\n",
        "                       degree, f'Polynomial Regression')\n",
        "\n",
        "        results.append({\n",
        "            'degree': degree,\n",
        "            'theta': theta,\n",
        "            'train_mse': train_mse,\n",
        "            'test_mse': test_mse\n",
        "        })\n",
        "\n",
        "        print(f\"\\nDegree {degree} Polynomial Regression:\")\n",
        "        print(f\"Coefficients (theta): {theta}\")\n",
        "        print(f\"Training MSE: {train_mse:.6f}\")\n",
        "        print(f\"Test MSE: {test_mse:.6f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run the analysis\n",
        "results = run_polynomial_regression('data.csv')"
      ],
      "metadata": {
        "id": "pdrN9tX2nupA",
        "outputId": "307f1aab-4c0c-46c8-81e7-b637a0ca37f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string '-3.292157,-53.468412' to float64 at row 0, column 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5a5abdb7c355>\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Run the analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_polynomial_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-5a5abdb7c355>\u001b[0m in \u001b[0;36mrun_polynomial_regression\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_polynomial_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Load and split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_split_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-5a5abdb7c355>\u001b[0m in \u001b[0;36mload_and_split_data\u001b[0;34m(filename, train_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load and split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_split_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m     arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiplines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mread_dtype_via_object_chunks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m             arr = _load_from_filelike(\n\u001b[0m\u001b[1;32m   1017\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m                 \u001b[0mimaginary_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimaginary_unit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string '-3.292157,-53.468412' to float64 at row 0, column 1."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b148fc9bfa8b60132af830e32e1690e4e023b803e92912df15b823b90141dda6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}